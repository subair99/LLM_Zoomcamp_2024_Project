{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb53424-5e8a-4de2-895b-aa88a13b0bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-16 12:00:51--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-10-16 12:00:52 (22.3 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install minsearch\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f35b1666-5393-458a-b747-177c1a1525ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required modules.\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import minsearch\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f98df4-326c-4a0f-95a3-2441e1ced3ca",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acee6281-a506-4dc0-9f82-8b2ad48346ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data for the project.\n",
    "df = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "916e2d08-7b1e-4837-87d2-29345003eb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "      <th>focus_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>There are many different types and designs of ...</td>\n",
       "      <td>NIHSeniorHealth</td>\n",
       "      <td>Knee Replacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>- a need to urinate frequently, especially at ...</td>\n",
       "      <td>NIHSeniorHealth</td>\n",
       "      <td>Prostate Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Who Should Be Tested? The United States Preven...</td>\n",
       "      <td>NIHSeniorHealth</td>\n",
       "      <td>Osteoporosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Risk Factors Diabetes and high blood pressure ...</td>\n",
       "      <td>NIHSeniorHealth</td>\n",
       "      <td>Kidney Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Kidney Disease Kidney disease is often called ...</td>\n",
       "      <td>NIHSeniorHealth</td>\n",
       "      <td>Kidney Disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             answer           source  \\\n",
       "0   0  There are many different types and designs of ...  NIHSeniorHealth   \n",
       "1   1  - a need to urinate frequently, especially at ...  NIHSeniorHealth   \n",
       "2   2  Who Should Be Tested? The United States Preven...  NIHSeniorHealth   \n",
       "3   3  Risk Factors Diabetes and high blood pressure ...  NIHSeniorHealth   \n",
       "4   4  Kidney Disease Kidney disease is often called ...  NIHSeniorHealth   \n",
       "\n",
       "         focus_area  \n",
       "0  Knee Replacement  \n",
       "1   Prostate Cancer  \n",
       "2      Osteoporosis  \n",
       "3    Kidney Disease  \n",
       "4    Kidney Disease  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of df.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92bdbd8d-eef7-4f2a-a55b-37e7c17f17b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the documents for analysis.\n",
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "267f9429-4f31-4750-bdf4-84d0a3ec554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the documents.\n",
    "index = minsearch.Index(\n",
    "    text_fields=['answer', 'source', 'focus_area'],\n",
    "    keyword_fields=['id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d734c998-f4a5-4390-9708-6c1edda23348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x74099c09ecf0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the index on the documents.\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f70bc03-575d-4576-8b1d-f82462feb485",
   "metadata": {},
   "source": [
    "## RAG Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bcd360d-3813-469b-bec6-0d5a7dffcb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the key.\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0eef0c9-3e59-4b02-9f49-57f7ae78e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the client.\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96687ff0-3348-4743-a56a-786127c84fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search function.\n",
    "def search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2450e48b-b4e3-4555-9e01-5674c3ff0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt_template.\n",
    "prompt_template = \"\"\"\n",
    "You're an excellent medical assistant. Answer the QUESTION based on the CONTEXT from our medical database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "CONTEXT: {context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ba389f5-d362-454e-b70f-261ac00132ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the entry_template.\n",
    "entry_template = \"\"\"\n",
    "answer: {answer}\n",
    "source: {source}\n",
    "focus_area: {focus_area}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a06cc5d9-3ce9-492c-8325-237aa6c8942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define build_prompt function.\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3881e794-a85b-4bd2-a9a0-ae5ab1021776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define llm function.\n",
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d1d1c70-a21d-4af7-8168-22215303687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rag function.\n",
    "def rag(query, model='gpt-4o-mini'):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c77a0a9e-3955-405f-8bff-66214f79e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some risk factors that might prompt a doctor to evaluate a patient for osteoporosis include:\n",
      "\n",
      "- Being a woman aged 65 or older\n",
      "- Being a woman younger than 65 and at high risk for fractures\n",
      "- Being a man or woman over age 50 who has broken a bone\n",
      "- Experiencing a loss of height, a stooped or hunched posture, or sudden back pain with no apparent cause\n",
      "- Taking glucocorticoid medications (such as prednisone, cortisone, or dexamethasone) for 2 months or longer or taking other medications known to cause bone loss\n",
      "- Having a chronic illness or taking medication known to cause bone loss\n",
      "- Having anorexia nervosa or a history of this eating disorder\n",
      "- Being a premenopausal woman, not pregnant, with stopped, irregular, or never-started menstrual periods upon reaching puberty.\n"
     ]
    }
   ],
   "source": [
    "# Ask a question and print the answer.\n",
    "question = 'What are some risk factors that might prompt a doctor to evaluate a patient for osteoporosis?'\n",
    "answer = rag(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100bd80-431d-4990-98f7-0ef5ed0fd174",
   "metadata": {},
   "source": [
    "## Retrieval Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a88433ad-dcc1-4455-a0df-3006b43c52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df_question.\n",
    "df_question = pd.read_csv('../data/ground-truth-retrieval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6525af2-4c66-4f4a-88c2-91e0b6b8dc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What are the main components of an artificial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the difference between total knee repl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>How are the components of a knee joint attache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>What are the advantages of minimally invasive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>What should I consider if I am interested in h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question\n",
       "0   0  What are the main components of an artificial ...\n",
       "1   0  What is the difference between total knee repl...\n",
       "2   0  How are the components of a knee joint attache...\n",
       "3   0  What are the advantages of minimally invasive ...\n",
       "4   0  What should I consider if I am interested in h..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of df_question.\n",
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e41a0aa-8f78-4aeb-b334-dd963d63a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ground_truth documents.\n",
    "ground_truth = df_question.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c86b03ae-5a68-4ac4-9314-00b521b56272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0, 'question': 'What are the main components of an artificial knee?'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first document in ground_truth.\n",
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ad9e893-c880-4af5-b6df-4a9b2806d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hit_rate function.\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75483b7a-4e9d-418f-8119-e18d2a1ca886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mrr function.\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d576457-2365-49bc-a573-df306e999c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the minsearch_search function.\n",
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bde9bbdd-f1a3-4e73-8538-d2591ed159c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluate function.\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2dd4e92-ca43-4b0c-ae47-6ec89b83a622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02a0dc3c85f4e8aa1f8ec28e14ecd48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9878787878787879, 'mrr': 0.8851875901875906}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the evaluation function.\n",
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95137144-7060-4e4c-aba5-359de3085144",
   "metadata": {},
   "source": [
    "## Finding Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "387e641c-6592-4e4f-b191-1e5ca7598f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df_question into df_validation and df_test.\n",
    "df_validation = df_question[:100]\n",
    "df_test = df_question[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a95c044-df61-4cb6-84a9-19ff9e1ef107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the simple_optimize function.\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "        \n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "        \n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6535225c-aa11-4875-895e-f84f2020083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gt_val documents.\n",
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33d2c962-b56a-4f1d-892a-1b84e89f4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new minsearch_search function with boost.\n",
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d61d688-45a0-40c9-bf5a-e87ad778ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter ranges.\n",
    "param_ranges = {\n",
    "    'answer': (0.0, 3.0),\n",
    "    'source': (0.0, 3.0),\n",
    "    'focus_area': (0.0, 3.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d264a51-7577-48c1-81fa-4ecdaf42ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective and search_function function.\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    \n",
    "    return results['mrr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85f903c6-9c07-4399-9cca-e12bda23e7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08472c46535d4c91952a6f9475d606ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ef54999233495aac1f85c3962c0913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd8113b44bc4466a2d04544c68ca39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e492f9af14594a9e94275976c7683a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09758d07ae4941a589d47e9500cf9ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601efb3400104521a1e625b3149f92bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18e8d4956484abc835b317c5b1d8e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa7e3e47b92483b953c4269336a6332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884fcb14cbb84828a0f4764b24821ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6e9cc7a1944b91918e99f789684509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cfb2ba18394777b41ad7dcc9da58a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b361d79a334443cd95cc86f7b6ad9220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf1e63f87ea4f6e9d9dd33743c535f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732b01ccf4b546e682aacbac488f4043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00a5826fb2643538370f11e8ef6f418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9ec65c00ea4fd4857e4a01e1206f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f687b6f424494fb1fb378e6e75e80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d4f501de224494ae23bc58cdae49bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a45e2175674d8b939d11f9ae03b132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d52bf8374b448b98995ca7355864084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'answer': 1.0812377449535782,\n",
       "  'source': 2.6054399406994126,\n",
       "  'focus_area': 0.6008972544485423},\n",
       " 0.8778333333333334)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the optimization.\n",
    "simple_optimize(param_ranges, objective, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e11a1b9-9375-4c24-bfb3-0170ce82187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the minsearch_improved function.\n",
    "def minsearch_improved(query):\n",
    "    boost = {\n",
    "        'answer':  1.0812377449535782,\n",
    "        'source': 2.6054399406994126,\n",
    "        'focus_area': 0.6008972544485423,\n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8339a8b3-d2ef-4ba6-936d-8ee615860d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decd4db287e041d6b28ba3daa8f933a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.990909090909091, 'mrr': 0.9296151996152001}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the ground_truth.\n",
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de669d5-f9a4-4da0-b533-2781204ece3b",
   "metadata": {},
   "source": [
    "## RAG Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ab3ae9a-8639-4244-ada3-90d321f0ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt2_template.\n",
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb3a0f2a-a232-4864-bf43-c93578667914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the ground_truth length.\n",
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2be59fd-2d38-4aeb-a335-025dc1cab029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the first ground_truth document to record.\n",
    "record = ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee516527-e088-4e0d-be34-6401149a723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the question from record.\n",
    "question = record['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "299c93ab-08e6-47cc-9ee3-52c80896eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the answer_llm with rag function)\n",
    "answer_llm = rag(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f1a5c96-6904-4cd6-8f36-4c6f56ead161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main components of an artificial knee are:\n",
      "\n",
      "1. The femoral component, which attaches to the thigh bone.\n",
      "2. The tibial component, which attaches to the shin bone.\n",
      "3. The patellar component, which is the knee cap.\n"
     ]
    }
   ],
   "source": [
    "# Print answer_llm.\n",
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "311e3d42-30a4-4fe7-906c-c3806442bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: What are the main components of an artificial knee?\n",
      "Generated Answer: The main components of an artificial knee are:\n",
      "\n",
      "1. The femoral component, which attaches to the thigh bone.\n",
      "2. The tibial component, which attaches to the shin bone.\n",
      "3. The patellar component, which is the knee cap.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print the prompt.\n",
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49056741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sample dataframe for the evaluation.\n",
    "df_sample = df_question.sample(n=200, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6decbd99-3f47-4c32-a93d-62aa8fb7151c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>176</td>\n",
       "      <td>What is urinary retention and how does it affe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>58</td>\n",
       "      <td>How does low health literacy affect individual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>194</td>\n",
       "      <td>What symptoms might indicate that someone has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>111</td>\n",
       "      <td>What lifestyle changes should be made to help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>31</td>\n",
       "      <td>What are the common signs or symptoms indicati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           question\n",
       "880  176  What is urinary retention and how does it affe...\n",
       "291   58  How does low health literacy affect individual...\n",
       "974  194  What symptoms might indicate that someone has ...\n",
       "556  111  What lifestyle changes should be made to help ...\n",
       "158   31  What are the common signs or symptoms indicati..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the head of df_sample.\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "417f0b05-ea06-4075-a588-750d434d6159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of df_sample.\n",
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94952ac1-408d-410f-95af-cd9ad180281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sample documents for the evaluation.\n",
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b3b89f-6070-465c-8d7f-ba4b0609da72",
   "metadata": {},
   "source": [
    "## Evaluate with gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a66cdc62-803c-4c79-a687-581788fe1d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e84981c8aad46a18631ee48a9728a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the questions with gpt-4o-mini.\n",
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question) \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf61170e-bfde-4889-8cd3-98fbfcc89918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the questions and create a dataframe.\n",
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9409cb0-c23a-48b1-92f2-c97497fd7c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           186\n",
       "PARTLY_RELEVANT      9\n",
       "NON_RELEVANT         5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract required data and show raw data.\n",
    "df_eval.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac52a63d-6d96-4116-a3d3-b906d52c2afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.930\n",
       "PARTLY_RELEVANT    0.045\n",
       "NON_RELEVANT       0.025\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract required data and show normalized data.\n",
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9492ff9c-d633-4d02-a573-217e3978ccbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The provided context does not contain any info...</td>\n",
       "      <td>13</td>\n",
       "      <td>What is the address of the U.S. Food and Drug ...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>The provided context does not contain any info...</td>\n",
       "      <td>13</td>\n",
       "      <td>Which organization can provide assistance with...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer indicates that there is n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>The context provided does not specify the freq...</td>\n",
       "      <td>77</td>\n",
       "      <td>What frequency of seizures is observed in pati...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>100</td>\n",
       "      <td>What regions are most affected by African Tryp...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer states that it cannot pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>100</td>\n",
       "      <td>What treatment options are available for someo...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer explicitly states that it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                answer   id  \\\n",
       "27   The provided context does not contain any info...   13   \n",
       "37   The provided context does not contain any info...   13   \n",
       "83   The context provided does not specify the freq...   77   \n",
       "105  The provided context does not contain specific...  100   \n",
       "143  The provided context does not contain specific...  100   \n",
       "\n",
       "                                              question     relevance  \\\n",
       "27   What is the address of the U.S. Food and Drug ...  NON_RELEVANT   \n",
       "37   Which organization can provide assistance with...  NON_RELEVANT   \n",
       "83   What frequency of seizures is observed in pati...  NON_RELEVANT   \n",
       "105  What regions are most affected by African Tryp...  NON_RELEVANT   \n",
       "143  What treatment options are available for someo...  NON_RELEVANT   \n",
       "\n",
       "                                           explanation  \n",
       "27   The generated answer does not provide any info...  \n",
       "37   The generated answer indicates that there is n...  \n",
       "83   The generated answer does not address the ques...  \n",
       "105  The generated answer states that it cannot pro...  \n",
       "143  The generated answer explicitly states that it...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the NON_RELEVANT rows in the dataframe.\n",
    "df_eval[df_eval.relevance == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b49b5637-48e5-43f3-a789-a960fd0c69ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datafran to csv in the data folder.\n",
    "df_eval.to_csv('../data/rag-eval-gpt-4o-mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f7b522-a8a1-4dfc-8484-39d926745ad5",
   "metadata": {},
   "source": [
    "## Evaluate with gpt-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4cd6ae64-67ee-4555-a909-f7cf43196a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed74973c1a24bbc9da05104bbc35d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the questions with gpt-4o.\n",
    "evaluations_gpt4o = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, model='gpt-4o') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations_gpt4o.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04e864b5-0061-4ae3-925a-7064fa0394e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the questions and create a dataframe.\n",
    "df_eval = pd.DataFrame(evaluations_gpt4o, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c54ecf16-8859-47a8-8bcc-4226c9214498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           184\n",
       "PARTLY_RELEVANT     10\n",
       "NON_RELEVANT         6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract required data and show raw data.\n",
    "df_eval.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ff27bcc-d843-499b-abf9-ff936303af22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.92\n",
       "PARTLY_RELEVANT    0.05\n",
       "NON_RELEVANT       0.03\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract required data and show normalized data.\n",
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4859cf7a-e4da-4b70-85f9-222a335571c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I'm unable to provide the address of the U.S. ...</td>\n",
       "      <td>13</td>\n",
       "      <td>What is the address of the U.S. Food and Drug ...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>The provided context does not contain informat...</td>\n",
       "      <td>154</td>\n",
       "      <td>What role does glycophorin A play in the trans...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>The provided CONTEXT does not include specific...</td>\n",
       "      <td>100</td>\n",
       "      <td>What regions are most affected by African Tryp...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>I'm sorry, but the CONTEXT provided does not c...</td>\n",
       "      <td>181</td>\n",
       "      <td>What are the main functions of the kidneys in ...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>The context provided from your medical databas...</td>\n",
       "      <td>197</td>\n",
       "      <td>What types of childhood nephrotic syndrome exist?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>I'm sorry, but the context provided does not c...</td>\n",
       "      <td>100</td>\n",
       "      <td>What treatment options are available for someo...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                answer   id  \\\n",
       "27   I'm unable to provide the address of the U.S. ...   13   \n",
       "94   The provided context does not contain informat...  154   \n",
       "105  The provided CONTEXT does not include specific...  100   \n",
       "141  I'm sorry, but the CONTEXT provided does not c...  181   \n",
       "142  The context provided from your medical databas...  197   \n",
       "143  I'm sorry, but the context provided does not c...  100   \n",
       "\n",
       "                                              question     relevance  \\\n",
       "27   What is the address of the U.S. Food and Drug ...  NON_RELEVANT   \n",
       "94   What role does glycophorin A play in the trans...  NON_RELEVANT   \n",
       "105  What regions are most affected by African Tryp...  NON_RELEVANT   \n",
       "141  What are the main functions of the kidneys in ...  NON_RELEVANT   \n",
       "142  What types of childhood nephrotic syndrome exist?  NON_RELEVANT   \n",
       "143  What treatment options are available for someo...  NON_RELEVANT   \n",
       "\n",
       "                                           explanation  \n",
       "27   The generated answer does not provide any rele...  \n",
       "94   The generated answer does not address the ques...  \n",
       "105  The generated answer does not provide any info...  \n",
       "141  The generated answer does not address the ques...  \n",
       "142  The generated answer does not provide any info...  \n",
       "143  The generated answer does not provide any info...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the NON_RELEVANT rows in the dataframe.\n",
    "df_eval[df_eval.relevance == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ade00f45-1aaf-4236-9452-cdd4bb47fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datafran to csv in the data folder.\n",
    "df_eval.to_csv('../data/rag-eval-gpt-4o.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f9d4d-c00c-4f90-bc9d-fd2ec4b0da58",
   "metadata": {},
   "source": [
    "## The run metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9e18194-0d69-484c-b12a-6b9230aa8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the run metrics.\n",
    "result_data = {'gpt-4o-mini':  ['$0.19', '22:13'], 'gpt-4o': ['$1.62', '28:15']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5eeba979-b2cb-4fdb-a698-701bc39adb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert collected metrics to dataframe.\n",
    "df_result_data = pd.DataFrame.from_dict(data=result_data, orient='index', columns=['total_cost', 'run_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0dfa4df9-dd08-4a57-b37a-7784ff8ec631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_cost</th>\n",
       "      <th>run_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>$0.19</td>\n",
       "      <td>22:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>$1.62</td>\n",
       "      <td>28:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_cost run_time\n",
       "gpt-4o-mini      $0.19    22:13\n",
       "gpt-4o           $1.62    28:15"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the dataframe.\n",
    "df_result_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
